---
author: "patrick.unicorn"
output:
  html_document:
    css: ../../css/main.css
    highlight: null
    theme: null
---

读《Java Performance: The Definitive Guide》

* * *

+ JVM 性能调优的过程实际上与 C++ 程序员在编译时通过测试选择编译参数，以及 PHP 码农在 php.ini
文件中选择适当变量等过程非常类似。

+ 编码和调优常常被认为是两个不同的专业领域：性能调优工程师只是竭力将 JVM的性能发挥到极致，而开发人员只关心他们的代码逻辑是否正确。这种区分没有什么意义。任何从事Java相关工作的人都应该熟谙代码在 JVM 中的行为，以及如何调优才能提升性能。

+ 商业版 JVM 中和性能密切相关的一个特性就是 Java 飞行记录器（Java Flight Recorder，JFR）。

+ 除了少数例外，JVM 主要接受两类标志：布尔标志和附带参数的标志。

+ 布尔标志采用以下语法： -XX:+FlagName 表示开启， -XX:-FlagName 表示关闭。

+ 附带参数的标志采用以下语法： -XX:FlagName=something ，表示将标志 flagName 的值设置为 something 。其中 something 通常可以为任意值。例如 -XX:NewRatio=N ，表示 NewRatio可以设置为任意值 N。

+ 在给定的命令行上，添加 -XX:+Printflagsfinal （默认为 false ，即“关闭” ）就能获得具体运行环境中特定标志的默认值。

+ 需要更高性能时，算法是否优秀就是重中之重了。

+ 要创建和销毁的对象越多，垃圾收集的工作量就越大；要分配和持有的对象越多，GC 的周期就越长；要从磁盘装载进 JVM 的类越
多，程序启动所花费的时间就越长；要执行的代码越多，机器硬件缓存的效率就越低；而执行的代码越多，花费的时间就越长。

+ 随着新特性的添加和新要求的采纳（为了与对手竞争） ，程序会越来越大，越来越慢。

+ “我们不应该把大量时间都耗费在那些小的性能改进上；过早考虑优化是所有噩梦的根源” 。这句名言的重点是，最终你应该编写清晰、直接、易读和易理解的代码。这里的“优化”应该理解为虽然算法和设计改变了复杂程序的结构，但是提供了更好的性能。那些真正的优化最好留到以后，等到性能分析表明这些措施有巨大收益的时候才进行。而这里所指的过早优化，并不包括避免那些已经知道对性能不好的代码结构。每行代码，如果有两种简单、直接的编程方式，那就应该选择性能更好的那种。

+ 常用的打印日志中，如果有拼接字符串的消息，应该首先判断日志是否开启，以避免不必要的字符串连接开销，比如：

```
// 不好
log.log(Level.FINE, "I am here, and the value of X is" 
    + calcX() + " and Y is " + calcY());
    
// 优化
if (log.isLoggable(Level.FINE)) {
    log.log(Level.FINE,
        "I am here, and the value of X is {} and Y is {}",
        new Object[]{calcX(), calcY()});
}
```

+ 在分布式环境中，比如 Java EE 应用服务器、负载均衡器、数据库和后台企业信息系统，Java 应用服务
器的性能问题可能只是其中很小的部分。

+ 对于整体系统，我们需要采取结构化方法针对系统的所有方面分析性能。CPU使用率、I/O延迟、系统整体的吞吐量都必须测量和分析。只有到那时，我们才能判定到底是哪个组件导致了性能瓶颈。

+ 增加系统某个组件的负载从而导致整个系统性能变慢，这项原则不仅限于数据库。CPU密集型的应用服务器增加负载，或者越来越多线程试图获取已经有线程等待的锁，还有许多其他场景，也都适用这项原则。

+ 优化的原则：

<blockquote>
+ 借助性能分析来优化代码，重点关注性能分析中最耗时的操作。然而请注意，这并不意
味着只看性能分析中的叶子方法 。

+ 利用奥卡姆剃刀原则诊断性能问题。性能问题最可能的原因应该是最容易解释的：新代
码比机器配置更可能引入性能问题，而机器配置比 JVM 或者操作系统的 bug 更容易引
入性能问题。隐藏的 bug 确实存在，但不应该把最可能引起性能问题的原因首先归咎于
它，而只在测试用例通过某种方式触发了隐藏的 bug 时才关注。但不应该一上来就跳到
这种不太可能的场景。

+ 为应用中最常用的操作编写简单算法。以估算数学公式的程序为例，用户可以决定他所
期望的最大容许误差为 10% 或 1%。如果 10% 的误差适合多数用户，那么优化代码就
意味着即便误差范围缩小为 1%，但是速度变慢了
</blockquote>

+ **微基准测试**用来测量微小代码单元的性能，包括调用同步方法的用时与非同步方法的用时比较，创建线程的代价与使用线程池的代价，执行某种算法的耗时与其替代实现的耗时，等等。相当于测试函数或代码片段。

+ 编写多线程微基准测试时务必深思熟虑。当若干个线程同时执行小段代码时，极有可能会产生同步瓶颈（以及其他线程问题） 。所以，如果我们过多依赖多线程基准测试的结果，就常常会将大量时间花费在优化那些真实场景中很少出现的同步瓶颈上，而不是性能需求更迫切的地方。

+ 考虑这样的微基准测试，即有两个线程同时调用同步方法。由于基准测试的代码量相对于被测方法来说比较少，所以多数时间都是在执行同步方法。假设执行同步方法的时间只占整个微基准测试的 50%，即便少到只有两个线程，同时执行同步代码的概率仍然很高。因此基准测试运行得很慢，并且随着线程数的增加，竞争所导致的性能问题将愈演愈烈。最终结果就是，测试衡量的是 JVM 如何处理竞争，而不是微基准测试的本来目的。

+ 微基准测试中的输入值必须事先计算好，不能使用随机数生成函数放在测试代码中，因为，随机生成函数也要耗费时间。

+ 我们应该为常见的场景进行优化，即使需要加入特殊的处理逻辑。

+ Java 的一个特点就是代码执行的越多性能越好，基于这点，微基准测试应该包括热身期，使得编译器能生成优化的代码。

+ 在做回归测试的时候，追踪级别设为纳秒很有意义。如果集合操作每次都节约几纳秒，日积月累下来意义就很重大了。对于那些不频繁的操作来说，例如那种同时只需处理一个请求的 servlet，修复微基
准测试所发现的纳秒级性能衰减就是浪费时间，这些时间用在优化其他操作上可能会更有价值。微基准测试难于编写，真正管用的又很有限。所以，应该了解这些相关的隐患后再做出决定，是微基准测试合情合理值得做，还是关注宏观的测试更好。

+ 衡量应用性能最好的事物就是应用自身，以及它所用到的外部资源。如果正常情况下应用需要调用 LDAP 来检验用户凭证，那应用就应该在这种模式下测试。虽然删空 LDAP 调用在模块测试中有一定意义，但应用本身必须在完整真实配置的环境中测试。

+ 任何应用（包含独立运行的 JVM）都可以像这样划分成一系列步骤，方框中的模块、子系统等产生数据的速度取决于它们的效率。（耗费的时间包括子系统代码的执行时间，也包括网络传输的时间、磁盘传输的时间，等等。如果是模块化的模型，时间应该只包括该模块内代码的执行时间。）数据进入子系统的速率取决于前一个模块或系统的输出速率。

+ 全应用测试有个很重要的场景，就是同一台机器上同时运行多个应用。许多 JVM 的默认调优都是默认假定整个机器的资源都归 JVM 使用。如果单独测试，优化效果很好。如果在其他应用（包括但不限于 Java 程序）运行的时候进行测试，性能会有很大的不同。

+ 单个 JVM（默认配置）执行 GC 周期时，该机器上所有处理器的 CPU 使用率都会变成 100%。如果测量程序执行时的平均CPU 使用率，大概会有 40%——实际意思是，某些时候 30%的CPU被占用，其他时候为100%。当隔离 JVM 时，它可以运行得很好，但如果 JVM 与其他应用并发运行，它就不可能在 GC 时获得 100% 的CPU。此时测出来的性能会与它单独运行时不同。这是微基准测试和模块测试不可能让你全面了解应用性能的另一个原因。

+ 不进行整体应用的测试，就不可能知道哪部分的优化会产生回报。

+ 使 Java 代码更快的常用方法是更好的算法，这不依赖Java 调优或者 Java 编码实践。

+ 虚拟机会花几分钟（或更长时间）全面优化代码并以最高性能执行。由于这个（以及其他）原因，研究Java的性能优化就要密切注意代码优化的热身期：大多数时候，应该在运行代码执行足够长时间，已经编译并优化之后再测量性能。

+ 许多情况下应用从开始到结束的整体性能更为重要。报告生成器处理 10 000 个数据元素需要花费大量时间，但对最终用户而言，处理前 5000个元素是否比后5000个慢50%并不重要。即便是像应用服务器这样的系统——其性能必定会随运行时间而改善——初始的性能依然很重要。某种配置下的应用服务器需要 45 分钟才能达到性能峰值。

+ 在客户端 - 服务器的吞吐量测试中，并不考虑客户端的思考时间。客户端向服务器发送请求，当它收到响应时，立刻发送新的请求。持续这样的过程，等到测试结束时，客户端会报告它所完成的操作总量。客户端常常有多个线处理，所以吞吐量就是所有客户端所完成的操作总量。通常这个数字就是每秒完成的操作量，而不是测量期间的总操作量。这个指标常常被称作每秒事务数（TPS） 、每秒请求数（RPS）或每秒操作次数（OPS） 。

+ 由于客户端线程需要执行大量工作，零思考时间（面向吞吐量）测试更可能会遇到这种情形。因此，通常吞吐量测试比响应时间测试的线程数少，线程负载也小。通常吞吐量测试也会报告请求的平均响应时间。这是重要的信息，但它的变化并不表示性能有问题，除非报告的吞吐量相同。能够承受 500 OPS、响应时间 0.5 秒的服务器，它的性能要好过响应时间 0.3 秒但只有 400 OPS 的服务器。吞吐量测试总是在合适的热身期之后进行。

+ 响应时间测试和吞吐量测试（假设后者是基于客户端 - 服务器模式）之间的差别是，响应时间测试中的客户端线程会在操作之间休眠一段时间。这被称为思考时间。响应时间测试是尽量模拟用户行为：用户在浏览器输入URL，用一些时间阅读返回的网页，然后点击页面上的链接，花一些时间阅读返回的网页，等等。当测试中引入思考时间时，吞吐量就固定了：指定数量的客户端，在给定思考时间下总是得到相同的 TPS（少许差别，参见框注） 。基于这点，测量请求的响应时间就变得重要了：服务器的效率取决于它响应固定负载有多快。

+ 性能测试的结果会随时间而变。即便程序每次处理的数据集都相同，产生的结果也仍然会有差别。因为有很多因素会影响程序的运行，如机器上的后台进程，网络时不时的拥堵等。好的基准测试不会每次都处理相同的数据集，而是会在测试中制造一些随机行为以模拟真实的世界。这就会带来一个问题：运行结果之间的差别，到底是因为性能有变化，还是因为测试的随机性。可用以下方法来解决这个问题，即多次运行测试，然后对结果求平均。当被测代码发生变化时，就再多次运行测试，对结果求平均，然后比较两个平均值。

+ 比较基准测试的结果时，我们不可能知道平均值的差异是真的性能有差还是随机涨落。最好的办法是先假设“平均值是一样的” ，然后确定该命题为真时的几率。如果命题很大几率为假，我们就有信心认为平均值是真的有差别（虽然我们永远无法 100% 肯定） 。注：《测试技术计量》课程，有一些对实验结果进行比对的方法。

+ 因代码更改而进行的测试称为回归测试。在回归测试中，原先的代码称为基线（baseline） ，而新的代码称为试样（specimen） 。

+ 
